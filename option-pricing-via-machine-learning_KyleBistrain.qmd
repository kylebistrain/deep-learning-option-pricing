---
title: Option Pricing via Machine Learning
aliases: 
  - ../option-pricing-via-machine-learning.html
metadata:
  pagetitle: Option Pricing via Machine Learning with R
  description-meta: Use machine learning tools such as random forests and deep neural networks to price call options using the programming language R.
---


```{r}
#| message: false
library(tidyverse)
library(tidymodels)
library(torch)
library(brulee)
library(hardhat)
library(ranger)
library(glmnet)
```

The package `torch` [@torch] provides functionality to define and train neural networks and is based on `PyTorch` [@PyTorch2019], while `brulee` [@brulee] provides several basic modeling functions that use the `torch` infrastructure. 
The package `ranger` [@ranger] provides a fast implementation for random forests and `hardhat` [@hardhat] is a helper function to for robust data preprocessing at fit time and prediction time.


## Neural Networks

Roughly speaking, neural networks propagate information from an input layer, through one or multiple hidden layers, to an output layer. While the number of units (neurons) in the input layer is equal to the dimension of the predictors, the output layer usually consists of one neuron (for regression) or multiple neurons for classification. The output layer predicts the future data, similar to the fitted value in a regression analysis. Neural networks have theoretical underpinnings as *universal approximators* for any smooth predictive association [@Hornik1991]. Their complexity, however, ranks neural networks among the least transparent, least interpretable, and most highly parameterized ML tools.
In finance, applications of neural networks can be found in many different contexts, e.g., @Avramov2022, @Chen2019, and @Gu2020.

Each neuron applies a non-linear *activation function* $f$ to its aggregated signal before
sending its output to the next layer
$$x_k^l = f\left(\theta^k_{0} + \sum\limits_{j = 1}^{N ^l}z_j\theta_{l,j}^k\right)$$
Here, $\theta$ are the parameters to fit, $N^l$ denotes the number of units (a hyperparameter to tune), and $z_j$ are the input variables which can be either the raw data or, in the case of multiple chained layers, the outcome from a previous layer $z_j = x_k-1$.
While the easiest case with $f(x) = \alpha + \beta x$ resembles linear regression, typical activation functions are sigmoid (i.e., $f(x) = (1+e^{-x})^{-1}$) or ReLu (i.e., $f(x) = max(x, 0)$).

Neural networks gain their flexibility from chaining multiple layers together. Naturally, this imposes many degrees of freedom on the network architecture for which no clear theoretical guidance exists. The specification of a neural network requires, at a minimum, a stance on depth (number of hidden layers), the activation function, the number of neurons, the connection structure of the units (dense or sparse), and the application of regularization techniques to avoid overfitting. Finally, *learning* means to choose optimal parameters relying on numerical optimization, which often requires specifying an appropriate learning rate. Despite these computational challenges, implementation in R is not tedious at all because we can use the API to `torch`. 


## Option Pricing

To apply ML methods in a relevant field of finance, we focus on option pricing. The application in its core is taken from @Hull2020. In its most basic form, call options give the owner the right but not the obligation to buy a specific stock (the underlying) at a specific price (the strike price $K$) at a specific date (the exercise date $T$). The Blackâ€“Scholes price [@Black1976] of a call option for a non-dividend-paying underlying stock is given by
$$
\begin{aligned}
  C(S, T) &= \Phi(d_1)S - \Phi(d_1 - \sigma\sqrt{T})Ke^{-r T} \\
     d_1 &= \frac{1}{\sigma\sqrt{T}}\left(\ln\left(\frac{S}{K}\right) + \left(r_f + \frac{\sigma^2}{2}\right)T\right)
\end{aligned}
$$
where $C(S, T)$ is the price of the option as a function of today's stock price of the underlying, $S$, with time to maturity $T$, $r_f$ is the risk-free interest rate, and $\sigma$ is the volatility of the underlying stock return. $\Phi$ is the cumulative distribution function of a standard normal random variable.

The Black-Scholes equation provides a way to compute the arbitrage-free price of a call option once the parameters $S, K, r_f, T$, and $\sigma$ are specified (arguably, in a realistic context, all parameters are easy to specify except for $\sigma$ which has to be estimated). A simple R function allows computing the price as we do below. 


```{r}
black_scholes_price <-function(S, K, r, T, sigma, type){
  # Input validation
  if (any(is.na(c(S, K, r, T, sigma, type)))) {
    warning("Inputs contain NA values.")
    return(NA)
  }
  
  if (!type %in% c("C", "P")) {
    stop("Invalid option type. Use 'C' for Call or 'P' for Put.")
  }

  if (S <= 0 || K <= 0) {
    warning("S and K must be positive.")
    return(NA)
  }

  if (T <= 0) {
    warning("Time to maturity T must be positive.")
    return(NA)
  }

  if (sigma <= 0) {
    warning("Volatility sigma must be positive.")
    return(NA)
  }

  if(type=="C"){
    d1 <- (log(S/K) + (r + sigma^2/2)*T) / (sigma*sqrt(T))
    d2 <- d1 - sigma*sqrt(T)

    price = S*pnorm(d1) - K*exp(-r*T)*pnorm(d2)
    return(price)}

  if (type=="P"){
    d1 <- (log(S/K) + (r + sigma^2/2)*T) / (sigma*sqrt(T))
    d2 <- d1 - sigma*sqrt(T)

    price =  (K*exp(-r*T)*pnorm(-d2) - S*pnorm(-d1))
    return(price)}
}
```


```{r}
# black_scholes_price <- function(S, K = 70, r = 0, T = 1, sigma = 0.2) {
#   
#   d1 <- (log(S / K) + (r + sigma^2 / 2) * T) / (sigma * sqrt(T))
#   d2 <- d1 - sigma * sqrt(T)
#   price <- S * pnorm(d1) - K * exp(-r * T) * pnorm(d2)
#   
#   return(price)
# }
```

## Learning Black-Scholes

We illustrate the concept of ML by showing how ML methods *learn* the Black-Scholes equation after observing some different specifications and corresponding prices without us revealing the exact pricing equation. 

### Data simulation

To that end, we start with simulated data. We compute option prices for call options for a grid of different combinations of times to maturity (`T`), risk-free rates (`r`), volatilities (`sigma`), strike prices (`K`), and current stock prices (`S`). In the code below, we add an idiosyncratic error term to each observation such that the prices considered do not exactly reflect the values implied by the Black-Scholes equation.

In order to keep the analysis reproducible, we use `set.seed()`. A random seed specifies the start point when a computer generates a random number sequence and ensures that our simulated data is the same across different machines. 

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os




```


```{r}
# Install and load quantmod
library(quantmod)

# Get Treasury yield data (e.g., 3-month T-bill rate)
getSymbols("DGS1MO", src="FRED")  # 1-month Treasury yield
getSymbols("DGS3MO", src="FRED")  # 3-month Treasury yield
getSymbols("DGS6MO", src="FRED")  # 6-month Treasury yield
getSymbols("DGS61", src="FRED")  # 1 year Treasury yield


head(DGS3MO)
sum(is.na(DGS3MO))

# For other durations:
# DGS1MO (1-month)
# DGS6MO (6-month)
# DGS1 (1-year)
# DGS10 (10-year)
```



```{python}
risk_free_interest = pd.read_csv('/Users/kylebistrain/Downloads/DGS3MO.csv', na_values=["."])

risk_free_interest['DATE'] = pd.to_datetime(risk_free_interest['DATE'])

risk_free_interest['DATE'] = risk_free_interest['DATE'].dt.strftime('%m/%d/%Y')

risk_free_interest.head()
# Return rows where DGS3MO is missing (NA)
print(risk_free_interest[risk_free_interest['DGS3MO'].isna()])
```
```{python}
def read_all_csv_files(directory_path):
    # List to store each monthly DataFrame
    all_data = []
    
    # Iterate through the directory and read each CSV file
    for filename in sorted(os.listdir(directory_path)):
        # Only process files that have a date range in the name, skip year-only files
        if filename.startswith("SPY_") and filename.endswith(".csv") and "to" in filename:
            file_path = os.path.join(directory_path, filename)
            print(f"Reading file: {file_path}")
            df = pd.read_csv(file_path)
            all_data.append(df)

    # Concatenate all DataFrames into one
    combined_data = pd.concat(all_data, ignore_index=True)
    
    return combined_data

# Example usage:
# Replace this with your actual directory path
directory_path = '/Users/kylebistrain/Documents/GREENCANVAS2024/Batch_45WQP5WXK5/'

# Call the function to read and combine all CSVs
combined_data = read_all_csv_files(directory_path)

# Display combined data
print(combined_data.head())

# Proceed with further analysis on `combined_data`

```
```{python}
combined_data.head(1000)
```
```{python}

combined_data['expiration'] = pd.to_datetime(combined_data['expiration'], format='%m/%d/%Y')
combined_data['quotedate'] = pd.to_datetime(combined_data['quotedate'], format='%m/%d/%Y')
combined_data['time_to_maturity'] = (combined_data['expiration'] - combined_data['quotedate']).dt.days

```

```{python}
import pandas as pd
missing_counts = combined_data.isnull().sum()
print("Missing Value Counts per Column:\n", missing_counts)
```
```{python}
import pandas as pd

filtered_df = combined_data[(combined_data['time_to_maturity'] >= 85) & 
                            (combined_data['time_to_maturity'] <= 95)]



filtered_df['quotedate'] = pd.to_datetime(filtered_df['quotedate'], errors='coerce')
risk_free_interest['DATE'] = pd.to_datetime(risk_free_interest['DATE'], errors='coerce')

print("NaT values in 'quotedate' column:", filtered_df['quotedate'].isna().sum())
print("NaT values in 'DATE' column:", risk_free_interest['DATE'].isna().sum())

merged_df = filtered_df.merge(risk_free_interest, how='left', left_on='quotedate', right_on='DATE')

merged_df.head()
```
```{python}
call_data = merged_df[(merged_df['type'] == 'call')]
put_data = merged_df[(merged_df['type'] == 'put')]
print(merged_df[merged_df['DGS3MO'].isna()])
```

```{python}
print(merged_df.size)
print(call_data.size)
print(put_data.size)

merged_df.to_csv("merged_df.csv", index=False)

```
```{r}
merged_df <- read.csv("/Users/kylebistrain/Documents/STATISTICS MASTERS/Thesis Code/merged_df.csv")


```
```{r}

library(dplyr)


merged_df %>%
  mutate(month = month(quotedate, label = TRUE)) %>%
  group_by(month) %>%
  summarise(n = n())

#plot(merged_df$n, merged_df$month)
```

```{r}

option_prices <- merged_df %>%
  mutate(
    S = as.numeric(underlying_last), 
    K = as.numeric(strike),
    r = as.numeric(DGS3MO),
    T = as.numeric(time_to_maturity) / 365,
    sigma = as.numeric(impliedvol),
    p_price = as.numeric(bid) + (as.numeric(ask) - as.numeric(bid))/2 ,
    baspread = abs(as.numeric(bid) - as.numeric(ask)),
    type = type,
    expiration = as.Date.character(expiration),
    quotedate = as.Date.character(quotedate),
    volume = volume,
    openinterest = openinterest,
    moneyness = S - K
  ) %>% 
  mutate(black_scholes = black_scholes_price(S, K, r, T, sigma, "C")) %>% 
  filter(type == "call", moneyness < 15, moneyness >= -15 , !is.na(black_scholes_price))


is.na(option_prices$black_scholes)

sum(is.na(option_prices$DGS3MO))
```
```{r}
library(ggplot2)

ggplot(option_prices, aes(x = baspread)) +
  geom_histogram(binwidth = 0.01, fill = "green", color = "blue") +
  labs(
    title = "Histogram of Bid-Ask Spread for 3 month Option Expiration",
    x = "Bid-Ask Spread",
    y = "Frequency"
  ) +
  theme_minimal()
```

```{r}
hist(option_prices$p_price)
```

```{r}
hist(option_prices$T)
```

```{r}
run <- option_prices %>% 
  select(S,K,r,T, sigma,black_scholes, p_price, volume, openinterest,quotedate) %>% 
  drop_na(black_scholes)
```




The code above generates more than 1.5 million random parameter constellations. For each of these values, two *observed* prices reflecting the Black-Scholes prices are given and a random innovation term *pollutes* the observed prices. The intuition of this application is simple: the simulated data provides many observations of option prices - by using the Black-Scholes equation we can evaluate the actual predictive performance of a ML method, which would be hard in a realistic context were the actual arbitrage-free price would be unknown. 

Next, we split the data into a training set (which contains 1\% of all the observed option prices) and a test set that will only be used for the final evaluation. Note that the entire grid of possible combinations contains `r option_prices |> nrow()` different specifications. Thus, the sample to learn the Black-Scholes price contains only 31,489 observations and is therefore relatively small.

```{r}
train_data <- run %>%
  filter(quotedate >= as.Date("2018-04-01") & quotedate <= as.Date("2021-04-01"))


test_data <- run %>%
  filter(quotedate >= as.Date("2021-06-01") & quotedate <= as.Date("2022-12-01"))
#split <- initial_split(run, prop = 1/ 100)
```


We process the training dataset further before we fit the different ML models. We define a `recipe()` that defines all processing steps for that purpose. For our specific case, we want to explain the observed price by the five variables that enter the Black-Scholes equation. The *true* prices (stored in column `black_scholes`) should obviously not be used to fit the model. The recipe also reflects that we standardize all predictors to ensure that each variable exhibits a sample average of zero and a sample standard deviation of one.  

```{r}
rec <- recipe(p_price ~ .,
  data = run
) |>
  step_rm(black_scholes,quotedate) |>
  step_normalize(all_predictors())
```

### Single layer networks and random forests

Next, we show how to fit a neural network to the data. Note that this requires that `torch` is installed on your local machine. The function `mlp()` from the package `parsnip` provides the functionality to initialize a single layer, feed-forward neural network. The specification below defines a single layer feed-forward neural network with 10 hidden units. We set the number of training iterations to `epochs = 500`. The option `set_mode("regression")` specifies a linear activation function for the output layer. 

```{r}
nnet_model <- mlp(
  epochs = 500,
  hidden_units = 10,
  activation = "sigmoid",
  penalty = 0.0001
) |>
  set_mode("regression") |>
  set_engine("brulee", verbose = FALSE)
```

The `verbose = FALSE` argument prevents logging the results to the console. We can follow the straightforward `tidymodel` workflow as in [Factor Selection via Machine Learning](factor-selection-via-machine-learning.qmd): define a workflow, equip it with the recipe, and specify the associated model. Finally, fit the model with the training data. 

```{r}
nn_fit <- workflow() |>
  add_recipe(rec) |>
  add_model(nnet_model) |>
  fit(data = train_data)
```

### Deep neural networks

A deep neural network is a neural network with multiple layers between the input and output layers. By chaining multiple layers together, more complex structures can be represented with fewer parameters than simple shallow (one-layer) networks as the one implemented above. For instance, image or text recognition are typical tasks where deep neural networks are used [for applications of deep neural networks in finance, see, for instance, @Jiang2022; @Jensen2022].

Note that while the `tidymodels` workflow is extremely convenient, these more sophisticated multi-layer (so-called *deep*) neural networks are not supported by `tidymodels` yet (as of September 2022). Instead, an implementation of a deep neural network in R requires additional computational tools. For that reason, the code snippet below illustrates how to initialize a sequential model with three hidden layers ith 10 units per layer. \index{torch} The `brulee` package provides a convenient interface to `torch` and is flexible enough to handle different activation functions. 

```{r}
deep_nnet_model <- mlp(
  epochs = 500,
  hidden_units = c(10, 10, 10),
  activation = "sigmoid",
  penalty = 0.0001
) |>
  set_mode("regression") |>
  set_engine("brulee", verbose = FALSE)
```

To train the neural network, we provide the inputs (`x`) and the variable to predict (`y`) and then fit the parameters. Note the slightly tedious use of the method `extract_mold(nn_fit)`. Instead of simply using the *raw* data, we fit the neural network with the same processed data that is used for the single-layer feed-forward network. What is the difference to simply calling `x = training(data) |> select(-observed_price, -black_scholes)`? Recall that the recipe standardizes the variables such that all columns have unit standard deviation and zero mean. Further, it adds consistency if we ensure that all models are trained using the same recipe such that a change in the recipe is reflected in the performance of any model. A final note on a potentially irritating observation: `fit()` alters the model - this is one of the few instances, where a function in R alters the *input* such that after the function call the object `model` is not same anymore!

```{r}
deep_nn_fit <- workflow() |>
  add_recipe(rec) |>
  add_model(deep_nnet_model) |>
  fit(data = train_data)
```

### Universal approximation

Before we evaluate the results, we implement one more model. In principle, any non-linear function can also be approximated by a linear model containing the input variables' polynomial expansions. To illustrate this, we first define a new recipe, `rec_linear`, which processes the training data even further. We include polynomials up to the fifth degree of each predictor and then add all possible pairwise interaction terms. The final recipe step, `step_lincomb()`, removes potentially redundant variables (for instance, the interaction between $r^2$ and $r^3$ is the same as the term $r^5$). We fit a Lasso regression model with a pre-specified penalty term (consult [Factor Selection via Machine Learning](factor-selection-via-machine-learning.qmd) on how to tune the model hyperparameters).

```{r} 
rec_linear <- rec |>
  step_poly(all_predictors(),
    degree = 5,
    options = list(raw = TRUE)
  ) |>
  step_interact(terms = ~ all_predictors():all_predictors()) |>
  step_lincomb(all_predictors())

lm_model <- linear_reg(penalty = 0.01) |>
  set_engine("glmnet")

lm_fit <- workflow() |>
  add_recipe(rec_linear) |>
  add_model(lm_model) |>
  fit(data = train_data)
```

## Prediction Evaluation

Finally, we collect all predictions to compare the *out-of-sample* prediction error evaluated on 10,000 new data points. Note that for the evaluation, we use the call to `extract_mold()` to ensure that we use the same pre-processing steps for the testing data across each model. We also use the somewhat advanced functionality in `forge()`, which provides an easy, consistent, and robust pre-processor at prediction time. 


```{r}
# Sample your out-of-sample data
out_of_sample_data <- test_data |>
  slice_sample(n = 1619)

# Get predictions from both models
deep_pred <- predict(deep_nn_fit, out_of_sample_data) |>
  rename(`Deep NN` = .pred)

shallow_pred <- predict(nn_fit, out_of_sample_data) |>
  rename(`Single layer` = .pred)

# Combine predictions with actual data
predictive_performance <- bind_cols(
  out_of_sample_data,
  deep_pred,
  shallow_pred
) |>
  pivot_longer(
    cols = c("Deep NN", "Single layer"),
    names_to = "Model",
    values_to = "value"
  ) |>
  mutate(
    moneyness = S - K,
    pricing_error = abs(value - black_scholes)
  )

```

```{r}
out_of_sample_data <- test_data |>
  slice_sample(n = 1619)

predictive_performance <- deep_nn_fit |>
  predict(out_of_sample_data) |>
  rename("Deep NN" = .pred) |>
  bind_cols(nn_fit) |>
    predict(out_of_sample_data) |>
  rename("Single layer" = .pred) |>
  bind_cols(out_of_sample_data) |>
  pivot_longer("Deep NN":"Single layer", names_to = "Model") |>
  mutate(
    moneyness = (S - K),
    pricing_error = abs(value - black_scholes)
  )
```

In the lines above, we use each of the fitted models to generate predictions for the entire test dataset of option prices. We evaluate the absolute pricing error as one possible measure of pricing accuracy, defined as the absolute value of the difference between predicted option price and the theoretical correct option price from the Black-Scholes model.  We show the results graphically in @fig-431.\index{Graph!Prediction error}

```{r, cache = TRUE}
#| label: fig-431 
#| fig-cap: "Absolute prediction error in USD for the different fitted methods. The prediction error is evaluated on a sample of call options that were not used for training."
#| fig-alt: "Title: Prediction errors of call option prices for different models. The figure shows the pricing error of the different machine learning methods for call options for different levels of moneyness (strike price minus stock price). The figure indicates variation across the models and across moneyness. The random forest approach performs worst, in particular out of the money."
predictive_performance |>
  group_by(quotedate) |>
  arrange(moneyness) |>
  ggplot(aes(
    x = moneyness, 
    y = pricing_error, 
    # color = Model,
    # linetype = Model
    )) +
  # geom_jitter(alpha = 0.1) +
  # geom_smooth(se = FALSE, method = "gam", formula = y ~ s(x, bs = "cs")) +
  geom_path(aes(group = quotedate), alpha = 0.1) +
  facet_wrap(~Model, ncol = 2) + 
  labs(
    x = "Moneyness (S - K)", color = NULL,
    y = "Absolute prediction error (USD)",
    title = "Prediction errors of call option prices for different models",
    linetype = NULL
  ) +
  ylim(0,100)

# merged_df |>
#   filter(quotedate < ymd("2014-12-31"),
#          quotedate > ymd("2014-6-1"),
#          type == 'call') |>
#   filter(abs(underlying_last - strike) < 25) |>
#   group_by(quotedate) |>
#   arrange(underlying_last - strike) |>
#   ggplot(aes(x = underlying_last - strike, y = (bid + ask)/2)) +
#   geom_path(aes(group = quotedate), alpha = 0.1)
```

```{r}
train_data %>%
  mutate(month = month(quotedate, label = TRUE)) %>%
  group_by(month) %>%
  summarise(n = n())
```
```{r}
test_data %>%
  mutate(month = month(quotedate, label = TRUE)) %>%
  group_by(month) %>%
  summarise(n = n())
```



```{r}
library(dplyr)

average_error <- predictive_performance %>%
  group_by(Model) %>%
  summarise(mean_error = mean(pricing_error, na.rm = TRUE), med = median(pricing_error, na.rm = TRUE), BS = mean(abs(black_scholes - p_price)))

print(average_error)

```


The results can be summarized as follows:

1. All ML methods seem to be able to price call options after observing the training test set.
1. The average prediction errors increase for far in-the-money options. 
1. Random forest and the Lasso seem to perform consistently worse in predicting option prices than the neural networks.
1. The complexity of the deep neural network relative to the single-layer neural network does not result in better out-of-sample predictions.

## Exercises

1. Write a function that takes `y` and a matrix of predictors `X` as inputs and returns a characterization of the relevant parameters of a regression tree with 1 branch. 
1. Create a function that creates predictions for a new matrix of predictors `newX` based on the estimated regression tree. 
1. Use the package `rpart` to *grow* a tree based on the training data and use the illustration tools in `rpart` to understand which characteristics the tree deems relevant for option pricing.
1. Make use of a training and a test set to choose the optimal depth (number of sample splits) of the tree.
1. Use `brulee` to initialize a sequential neural network that can take the predictors from the training dataset as input, contains at least one hidden layer, and generates continuous predictions. *This sounds harder than it is: *see a simple [regression example here.](https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_basic_regression/) How many parameters does the neural network you aim to fit have? 
1. Compile the object from the previous exercise. It is important that you specify a loss function. Illustrate the difference in predictive accuracy for different architecture choices.
